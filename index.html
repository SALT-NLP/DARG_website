<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph">
  <meta name="keywords" content="DARG">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/salt-logo.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    /* Three image containers (use 25% for four, and 50% for two, etc) */
    .imgcolumn {
      float: left;
      width: 50%;
      padding: 10px
    }

    /* Clear floats after image containers */
    .imgrow::after {
      content: "";
      clear: both;
      display: table;
    }

    table.customTable {
      width: 50%;
      background-color: #FFFFFF;
      border-collapse: collapse;
      border-width: 2px;
      border-color: rgb(214, 236, 244);
      border-style: solid;
      color: #000000;
      margin-left: auto;
      margin-right: auto;
    }
    
    table.customTable td {
      border-width: 2px;
      border-color: rgb(214, 236, 244);
      border-style: solid;
      padding: 5px;
      text-align: center; 
      vertical-align: middle;
    }

    table.customTable th {
      border-width: 2px;
      border-color: rgb(214, 236, 244);
      border-style: solid;
      padding: 5px;
    }
    
    table.customTable thead {
      background-color: rgb(214, 236, 244);
    }
    </style>
</head>
<body>
  
  

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://zzh-sjtu.github.io/zhehaozhang.github.io/">Zhehao Zhang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://cs.stanford.edu/people/jiaaoc/">Jiaao Chen</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a><sup>3</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Dartmouth College,</span>
            <span class="author-block"><sup>2</sup>Georgia Tech,</span>
            <span class="author-block"><sup>3</sup>Stanford University,</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <img src="./static/images/Dartmouth-College-Logo.png" width="200" align="absmiddle" />
            </span>
            <span class="author-block">
              <img src="./static/images/GeorgiaTech_RGB.png" width="200" align="absmiddle"/>  
            </span>
            <span class="author-block">
              <img src="./static/images/stanford-university-logo-2.png" style="margin-right: 50px;" width="200" align="absmiddle"/>  
            </span><!---->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/SALT-NLP/DARG"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The current paradigm of evaluating Large Language Models (LLMs) through static benchmarks comes with significant limitations, such as vulnerability to data contamination and a lack of adaptability to the evolving capabilities of LLMs. Therefore, evaluation methods that can adapt and generate evaluation data with controlled complexity are urgently needed. In this work, we introduce Dynamic Evaluation of LLMs via Adaptive Reasoning Graph Evolvement (DARG) to dynamically extend current benchmarks with controlled complexity and diversity. Specifically, we first extract the reasoning graphs of data points in current benchmarks and then perturb the reasoning graphs to generate novel testing data. Such newly generated test samples can have different levels of complexity while maintaining linguistic diversity similar to the original benchmarks. We further use a code-augmented LLM to ensure the label correctness of newly generated data. We apply our DARG framework to diverse reasoning tasks in four domains with 15 state-of-the-art LLMs. Experimental results show that almost all LLMs experience a performance decrease with increased complexity and certain LLMs exhibit significant drops. Additionally, we find that LLMs exhibit more biases when being evaluated via the data generated by DARG with higher complexity levels. These observations provide useful insights into how to dynamically and adaptively evaluate LLMs.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Overall Framework</h2>
          <p>Our DARG framework we first construct the reasoning graphs for data points in given benchmarks using LLMs (e.g., computational reasoning graphs for solving a math problem are shown in the following figure). Next, we perform fine-grained graph perturbations based on various dimensions of the reasoning graph. Afterwards, we convert the reasoning graph back into the description that adapts the linguistic diversity as the original data. In order to ensure the correctness of the reasoning graph construction and graph-to-text generation, we use tool-augmented LLMs to verify the quality of reasoning graphs and generated text to produce valid test examples.</p>
          <img src="./static/images/framework.png" class="example-image" alt="Example image."/>
        </div>
      </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">MATH Reasoning</h2>
          <p>We evaluate 15 SOTA LLMs on GSM8K using DARG with reasoning graphs of increased width, depth, and numerical complexity. Almost all LLMs' performances drop, while closed-source models and larger models show more resilience to complexity increases.</p>
          <center><img src="./static/images/gsm8k_result_figure.png" class="example-image" alt="Example image." style="width: 80%;"/></center>
          <center><img src="./static/images/gsm8k_table.png" class="example-image" alt="Example image." style="width: 60%;" /></center>
          <center><img src="./static/images/radar.png" class="example-image" alt="Example image." style="width: 80%;" /></center>
          <p>This radar map shows different LLMs' resilience to complexity increases, measured by the Complexity-Induced Accuracy Retention Rate (CIARR), which calculates the average percentage retention in accuracy per complexity increment as the average ratio of accuracy at each subsequent complexity level to the previous level.</p>
        </div>
      </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Social Reasoning</h2>
          <p>We evaluate SOTA LLMs on the Bias Benchmark for QA (BBQ) using DARG with reasoning graphs that have an increased number of attribute nodes and modified attributes' polarity. The metrics are accuracy, bias score, and Overall Avoidance Rate, which measures how often LLMs are overly sensitive to contexts involving protected groups, often choosing 'Cannot be determined.' even when clear evidence supports an answer. LLMs perform worse as complexity increases and show increasing biases towards protected groups.</p>
          <center><img src="./static/images/bbq_cot_results.png" class="example-image" alt="Example image." style="width: 80%;" /></center>
        </div>
      </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Spatial Reasoning</h2>
          <p>We evaluate SOTA LLMs on the BBH Navigate dataset, a spatial reasoning dataset that involves giving the LLM navigation
          steps to determine if the agent returns to the starting point. As the depth of the reasoning graph increases, most LLMs'
          overall accuracy drops, with a significant decline in accuracy on positive cases (where the label is 'Yes') while the
          accuracy on negative cases remains comparatively stable, indicating biases.</p>
          <img src="./static/images/navigate_overall.png" class="example-image" alt="Example image."/>
          <img src="./static/images/navigate_negative.png" class="example-image" alt="Example image." />
          <img src="./static/images/navigate_positive.png" class="example-image" alt="Example image." />
        </div>
      </div>
    </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Model Comparison Examples</h2>
          <p>We present some case study examples to compare between different prompting methods and different models.</p>
          <img src="./static/images/text_augmentation_example.png" class="example-image" alt="Example image."/>
          <img src="./static/images/self_revision_examples.png" class="example-image" alt="Example image."/>
          <img src="./static/images/open_source_models.png" class="example-image" alt="Example image."/>
          
        </div>
      </div>
    </div>
</section>

<section class="section"  style="background-color:#d6eeff">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Additional GPT-4V Generation Examples</h2>
            <p>We present more examples of GPT-4V generated webpages in comparison with the original reference webpages. The original designs are on the left and the GPT-4V generated webpages are on the right. You can judge for yourself whether GPT-4V is ready to automate building webpages.</p>
                <div class="imgrow">
                  <div class="imgcolumn">
                    <img src="./static/images/testset_full_2.png" style="width:100%">
                  </div>
                  <div class="imgcolumn">
                    <img src="./static/images/gpt4v_visual_revision_prompting_2.png" style="width:100%">
                  </div>
                </div>
                <div class="imgrow">
                  <div class="imgcolumn">
                    <img src="./static/images/testset_full_13.png" style="width:100%">
                  </div>
                  <div class="imgcolumn">
                    <img src="./static/images/gpt4v_visual_revision_prompting_13.png" style="width:100%">
                  </div>
                </div>
                <div class="imgrow">
                  <div class="imgcolumn">
                    <img src="./static/images/testset_full_28.png" style="width:100%">
                  </div>
                  <div class="imgcolumn">
                    <img src="./static/images/gpt4v_visual_revision_prompting_28.png" style="width:100%">
                  </div>
                </div>
                <div class="imgrow">
                  <div class="imgcolumn">
                    <img src="./static/images/testset_full_33.png" style="width:100%">
                  </div>
                  <div class="imgcolumn">
                    <img src="./static/images/gpt4v_visual_revision_prompting_33.png" style="width:100%">
                  </div>
                </div>
                <div class="imgrow">
                  <div class="imgcolumn">
                    <img src="./static/images/testset_full_61.png" style="width:100%">
                  </div>
                  <div class="imgcolumn">
                    <img src="./static/images/gpt4v_visual_revision_prompting_61.png" style="width:100%">
                  </div>
                </div>
                <div class="imgrow">
                  <div class="imgcolumn">
                    <img src="./static/images/testset_full_89.png" style="width:100%">
                  </div>
                  <div class="imgcolumn">
                    <img src="./static/images/gpt4v_visual_revision_prompting_89.png" style="width:100%">
                  </div>
                </div>
        </div>
      </div>
    </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{zhang2024darg,
    title={DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph},
    author={Zhang, Zhehao and Chen, Jiaao and Yang, Diyi},
    journal={arXiv preprint arXiv:XXX},
    year={2024}
    }</code></pre>
  </div>
</section>


<section class="section" id="Acknowledgement">
  <div class="container is-max-desktop content">
    <h2 class="title">Usage and License Notices</h2>
    <p>
      The data, code and model checkpoint are intended and licensed for research use only. Please do not use them for any malicious purposes.
    </p>
    <p>
      The benchmark is built on top of the C4 dataset, under the ODC Attribution License (ODC-By). 
    </p>
    <p>
      This website is licensed under a <a rel="license"
                                          href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
      Commons Attribution-ShareAlike 4.0 International License</a>.
    </p>
    <p>
      This source code of this website is borrowed from <a
        href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
    </p>
  </div>
</section>


<!-- 
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This source code of this website is borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer> -->

</body>
</html>
